{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWhfybnGYiKi",
        "colab_type": "code",
        "outputId": "b2e0393e-5c92-4075-a700-211240791ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHmeBJWuYLrr",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0xzBgJYLrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import os\n",
        "from argparse import Namespace\n",
        "\n",
        "import unidecode\n",
        "import random\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8if1OYIUYLrw",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cuiQzyDYLrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = pd.read_table('data/reviews.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPpd1TomYLrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews.dropna(subset=['content'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAPHuVkQYLr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_from_dataframe(df, batch_size, seq_size):\n",
        "    \n",
        "    text = \" \".join(df.content.apply(unidecode.unidecode).values.flatten())\n",
        "    \n",
        "    text = text.split()\n",
        "\n",
        "    word_counts = Counter(text)\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
        "    n_vocab = len(int_to_vocab)\n",
        "\n",
        "    print('Vocabulary size', n_vocab)\n",
        "\n",
        "    int_text = [vocab_to_int[w] for w in text]\n",
        "    num_batches = int(len(int_text) / (seq_size * batch_size))\n",
        "    in_text = int_text[:num_batches * batch_size * seq_size]\n",
        "    out_text = np.zeros_like(in_text)\n",
        "    out_text[:-1] = in_text[1:]\n",
        "    out_text[-1] = in_text[0]\n",
        "    in_text = np.reshape(in_text, (batch_size, -1))\n",
        "    out_text = np.reshape(out_text, (batch_size, -1))\n",
        "    return int_to_vocab, vocab_to_int, n_vocab, in_text, out_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXvG-hxUYLr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(in_text, out_text, batch_size, seq_size):\n",
        "    num_batches = np.prod(in_text.shape) // (seq_size * batch_size)\n",
        "    for i in range(0, num_batches * seq_size, seq_size):\n",
        "        yield in_text[:, i:i+seq_size], out_text[:, i:i+seq_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHjrOe3xTiZF",
        "colab_type": "text"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06vkYdyceS3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def column_label_encoding(df, le_colname):\n",
        "  le = LabelEncoder()\n",
        "  df[le_colname] = le.fit_transform(df[le_colname].to_list()) \n",
        "  return df\n",
        "\n",
        "def mean_score_encoding(df, grouping_columns, target_columns):\n",
        "  for target_column in target_columns:\n",
        "    mean_group = df.groupby(grouping_columns)[target_column].mean().reset_index()\n",
        "    mean_group.columns = grouping_columns + ['_'.join(grouping_columns) + '_mean_' + target_column]\n",
        "    df = df.merge(mean_group, on=grouping_columns)\n",
        "  return df\n",
        "\n",
        "def convert_string_to_date(date_time_str):\n",
        "  conversion = datetime.datetime.strptime(date_time_str, \"%Y-%m-%d\")\n",
        "  return conversion\n",
        "\n",
        "def change_date_for_column(df, column):\n",
        "    return df[column].apply(convert_string_to_date)\n",
        "\n",
        "def preprocess_knn(df):\n",
        "\n",
        "  df = df[[\"artist\", \n",
        "           \"score\", \n",
        "           \"pub_date\", \n",
        "           \"best_new_music\", \n",
        "           \"genre\", \n",
        "           \"label\", \n",
        "           \"acousticness\",\n",
        "           \"danceability\",\n",
        "           \"energy\",\n",
        "           \"instrumental\",\n",
        "           \"liveness\",\n",
        "           \"loudness\",\n",
        "           \"speechiness\",\n",
        "           \"tempo\",\n",
        "           \"valence\",\n",
        "           \"popularity\"\n",
        "  ]]\n",
        "  df = column_label_encoding(df, 'label')\n",
        "  df = mean_score_encoding(df, ['artist'], ['score'])\n",
        "  df['pub_date'] = change_date_for_column(df, 'pub_date')\n",
        "  df['pub_date'] = pd.to_numeric(df['pub_date'], errors='coerce')\n",
        "  df = pd.get_dummies(df.drop([\"artist\"], axis=1))\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZRGmFCsgdlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_KNN(df, n_neighbors):\n",
        "    neighs = NearestNeighbors(n_neighbors=n_neighbors)\n",
        "    neigs = neighs.fit(df)\n",
        "    _, indices = neighs.kneighbors(reviews_knn)\n",
        "        \n",
        "    return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNGirkUQhLpg",
        "colab_type": "code",
        "outputId": "dd55ac8c-f2b9-4f38-9cbf-f4b2f6743ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Get nearest neighbors for each album\n",
        "reviews_knn = preprocess_knn(reviews)\n",
        "neighborhoods = perform_KNN(reviews_knn, 16)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "builKM1XHdKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Selecting a random album to generate a review\n",
        "random_review_index = random.randint(0, reviews.shape[0])\n",
        "test_album = reviews.iloc[random_review_index]\n",
        "reviews = reviews.drop([random_review_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCMUzSL0JuFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Selecting reviews from nearest neighbors\n",
        "reviews_from_cluster = reviews.iloc[neighborhoods[random_review_index]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4OJJj2uT7DA",
        "colab_type": "text"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rK01GN-YLr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNModule(nn.Module):\n",
        "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
        "        super(RNNModule, self).__init__()\n",
        "        self.seq_size = seq_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size,\n",
        "                            lstm_size,\n",
        "                            batch_first=True)\n",
        "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
        "        \n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.dense(output)\n",
        "\n",
        "        return logits, state\n",
        "        \n",
        "    def zero_state(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
        "                torch.zeros(1, batch_size, self.lstm_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzyQxTRxZH4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loss_and_train_op(net, lr=0.001):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "        return criterion, optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paUkimOgYLr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flags = Namespace(\n",
        "    seq_size=32,\n",
        "    batch_size=32,\n",
        "    embedding_size=64,\n",
        "    lstm_size=64,\n",
        "    gradients_norm=5,\n",
        "    initial_words=['This', 'album'],\n",
        "    predict_top_k=5,\n",
        "    checkpoint_path='checkpoint',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv-1QFpAYLr_",
        "colab_type": "code",
        "outputId": "e753755b-6008-4dfb-d196-ee045566fadc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHMtICQnODTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLT0gi6hZ_qR",
        "colab_type": "code",
        "outputId": "e31cfc78-4ce8-426d-d936-56bd0fa9c715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reviews_index_to_train = reviews_from_cluster.index.tolist() + random.sample(range(reviews.shape[0]), 256)\n",
        "\n",
        "int_to_vocab, vocab_to_int, n_vocab, in_text, out_text = get_data_from_dataframe(\n",
        "    reviews.iloc[reviews_index_to_train], \n",
        "    flags.batch_size, \n",
        "    flags.seq_size\n",
        ")\n",
        "\n",
        "net = RNNModule(n_vocab, flags.seq_size, flags.embedding_size, flags.lstm_size)\n",
        "net = net.to(device)\n",
        "\n",
        "criterion, optimizer = get_loss_and_train_op(net, 0.05)\n",
        "\n",
        "iteration = 0"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size 36482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWoZxIxFYLsD",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqM5ECWdaSev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
        "    net.eval()\n",
        "\n",
        "    state_h, state_c = net.zero_state(1)\n",
        "    state_h = state_h.to(device)\n",
        "    state_c = state_c.to(device)\n",
        "    for w in words:\n",
        "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
        "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "    \n",
        "    _, top_ix = torch.topk(output[0], k=top_k)\n",
        "    choices = top_ix.tolist()\n",
        "    choice = np.random.choice(choices[0])\n",
        "\n",
        "    words.append(int_to_vocab[choice])\n",
        "    for _ in range(100):\n",
        "        ix = torch.tensor([[choice]]).to(device)\n",
        "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "\n",
        "        _, top_ix = torch.topk(output[0], k=top_k)\n",
        "        choices = top_ix.tolist()\n",
        "        choice = np.random.choice(choices[0])\n",
        "        words.append(int_to_vocab[choice])\n",
        "\n",
        "    print(' '.join(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obRAaoy2YLsE",
        "colab_type": "code",
        "outputId": "0bbe249c-9fd9-4786-e805-a85d5f6776e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "n_epochs = 20\n",
        "for e in range(n_epochs):\n",
        "    batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
        "    state_h, state_c = net.zero_state(flags.batch_size)\n",
        "\n",
        "    # Transfer data to GPU\n",
        "    state_h = state_h.to(device)\n",
        "    state_c = state_c.to(device)\n",
        "    for x, y in batches:\n",
        "        iteration += 1\n",
        "\n",
        "        # Tell it we are in training mode\n",
        "        net.train()\n",
        "\n",
        "        # Reset all gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Transfer data to GPU\n",
        "        x = torch.tensor(x).to(device)\n",
        "        y = torch.tensor(y).to(device)\n",
        "\n",
        "        logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
        "        loss = criterion(logits.transpose(1, 2), y)\n",
        "\n",
        "        state_h = state_h.detach()\n",
        "        state_c = state_c.detach()\n",
        "\n",
        "        loss_value = loss.item()\n",
        "\n",
        "        # Perform back-propagation\n",
        "        loss.backward()\n",
        "        \n",
        "        _ = torch.nn.utils.clip_grad_norm_(net.parameters(), flags.gradients_norm)\n",
        "\n",
        "        # Update the network's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        if iteration % 100 == 0:\n",
        "            print('Epoch: {}/{}'.format(e, n_epochs),\n",
        "                  'Iteration: {}'.format(iteration),\n",
        "                  'Loss: {}'.format(loss_value))\n",
        "\n",
        "    predict(device, net, flags.initial_words, n_vocab,\n",
        "                    vocab_to_int, int_to_vocab, top_k=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/20 Iteration: 100 Loss: 8.372857093811035\n",
            "This album that and a way of her first place. that and his first and a bit and and his own and the band to make its most hardcore first place. the band is a bit is a good that a lot in his music of a lot to a few of her and the same more personal Mind is an album and that a few and in the album the band and and and the way that that and and his music and and that the band that it to be the band of his own and his most Slugs in its\n",
            "Epoch: 1/20 Iteration: 200 Loss: 7.616166591644287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coiKe-oYzUF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}